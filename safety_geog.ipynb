{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_combos(crashes: pl.DataFrame, group_by_cols):\n",
    "    \"\"\"\n",
    "    Some groups have no crashes. This make sures these groups still have a row of 0s.\n",
    "    \"\"\"\n",
    "    # create a single row df with each col being a list of the unique values of that col\n",
    "    cross_product_df = crashes.select(pl.col(group_by_cols).unique().implode())\n",
    "    # create a cross product of the unique values of these cols\n",
    "    for col in group_by_cols:\n",
    "        # explode explodes the lists in each of these cols back out to different rows\n",
    "        cross_product_df = cross_product_df.explode(col)\n",
    "    return cross_product_df.join(\n",
    "        crashes, how=\"left\", on=group_by_cols, coalesce=True\n",
    "    ).with_columns(\n",
    "        pl.col(\"area_sqmi\").max().over(\"analysis_neighborhood\"),\n",
    "        pl.col(\"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\", \"ALL_ACCIDENT\").fill_null(0),\n",
    "    )\n",
    "\n",
    "\n",
    "def group_crashes(crashes: pl.DataFrame, time_col: str):\n",
    "    group_by_cols = [time_col, \"analysis_neighborhood\", \"severity\"]\n",
    "    crashes_grouped = generate_all_combos(\n",
    "        crashes.group_by(group_by_cols).agg(\n",
    "            # area_sqmi dependent on the 'analysis_neighborhood' col, but can't use\n",
    "            # group by directly, as it's a float and so the values are not exactly equal\n",
    "            pl.first(\"area_sqmi\"),\n",
    "            pl.sum(\"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\"),\n",
    "            ALL_ACCIDENT=pl.len(),\n",
    "        ),\n",
    "        group_by_cols,\n",
    "    )\n",
    "    # also calculate number of injury only + fatal crashes\n",
    "    return normalize_by_area(\n",
    "        pl.concat(\n",
    "            [\n",
    "                crashes_grouped,\n",
    "                crashes_grouped.group_by(time_col, \"analysis_neighborhood\").agg(\n",
    "                    pl.lit(\"combined\").alias(\"severity\"),\n",
    "                    pl.first(\"area_sqmi\"),\n",
    "                    pl.sum(\n",
    "                        \"PEDESTRIAN_ACCIDENT\",\n",
    "                        \"BICYCLE_ACCIDENT\",\n",
    "                        \"ALL_ACCIDENT\",\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        ).sort(group_by_cols)\n",
    "    )\n",
    "\n",
    "\n",
    "def sum_ped_and_bike(crashes_grouped):\n",
    "    return crashes_grouped.with_columns(\n",
    "        PED_AND_BIKE_ACCIDENT=pl.sum_horizontal(\n",
    "            \"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\"\n",
    "        ),\n",
    "        PED_AND_BIKE_ACCIDENT_per_sqmi=pl.sum_horizontal(\n",
    "            \"PEDESTRIAN_ACCIDENT_per_sqmi\", \"BICYCLE_ACCIDENT_per_sqmi\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_by_area(crashes_grouped: pl.DataFrame):\n",
    "    # normalizing by area rather than road-miles, because the road centrelines\n",
    "    # GIS file sometimes has 2 'roads' per segment of arterial (e.g. north/southbound\n",
    "    # are separate for Van Ness). I guess we can just count one-way-road-miles. But eh\n",
    "    # area is good enough\n",
    "    return crashes_grouped.with_columns(\n",
    "        PEDESTRIAN_ACCIDENT_per_sqmi=pl.col(\"PEDESTRIAN_ACCIDENT\")\n",
    "        / pl.col(\"area_sqmi\"),\n",
    "        BICYCLE_ACCIDENT_per_sqmi=pl.col(\"BICYCLE_ACCIDENT\") / pl.col(\"area_sqmi\"),\n",
    "        ALL_ACCIDENT_per_sqmi=pl.col(\"ALL_ACCIDENT\") / pl.col(\"area_sqmi\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_covid_change(crashes_grouped: pl.DataFrame, geog_col):\n",
    "    return (\n",
    "        crashes_grouped.filter(pl.col(\"covid_period\").is_in([\"2018-2019\", \"2022-2023\"]))\n",
    "        .sort(geog_col, \"severity\", \"covid_period\")\n",
    "        .with_columns(\n",
    "            # calculate % change with previous row\n",
    "            (\n",
    "                pl.col(\n",
    "                    # \"PEDESTRIAN_ACCIDENT\",\n",
    "                    # \"BICYCLE_ACCIDENT\",\n",
    "                    # \"ALL_ACCIDENT\",\n",
    "                    \"PED_AND_BIKE_ACCIDENT\"\n",
    "                ).pct_change()\n",
    "                * 100  # since pct_change gives it in fraction not %\n",
    "            ).name.suffix(\"_1819_to_2223_pct_change\"),\n",
    "            pl.col(\n",
    "                # \"PEDESTRIAN_ACCIDENT_per_sqmi\",\n",
    "                # \"BICYCLE_ACCIDENT_per_sqmi\",\n",
    "                # \"ALL_ACCIDENT_per_sqmi\",\n",
    "                \"PED_AND_BIKE_ACCIDENT_per_sqmi\"\n",
    "            )\n",
    "            .diff()\n",
    "            .name.suffix(\"_1819_to_2223_diff\"),\n",
    "        )\n",
    "        # only select every 2nd row (i.e. the post-covid rows)\n",
    "        .filter(pl.col(\"covid_period\") == \"2022-2023\")\n",
    "        .drop(\n",
    "            \"covid_period\",\n",
    "            \"PEDESTRIAN_ACCIDENT\",\n",
    "            \"BICYCLE_ACCIDENT\",\n",
    "            \"ALL_ACCIDENT\",\n",
    "            \"PED_AND_BIKE_ACCIDENT\",\n",
    "            \"PEDESTRIAN_ACCIDENT_per_sqmi\",\n",
    "            \"BICYCLE_ACCIDENT_per_sqmi\",\n",
    "            \"ALL_ACCIDENT_per_sqmi\",\n",
    "            \"PED_AND_BIKE_ACCIDENT_per_sqmi\",\n",
    "            strict=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "northeast_core_analysis_neighborhoods = {\n",
    "    \"Financial District/South Beach\",\n",
    "    \"Mission Bay\",\n",
    "    \"South of Market\",\n",
    "    \"Tenderloin\",\n",
    "    \"Nob Hill\",\n",
    "    \"Chinatown\",\n",
    "    \"North Beach\",\n",
    "    \"Russian Hill\",\n",
    "}\n",
    "\n",
    "\n",
    "def add_analysis_neighborhood_geometry(df, analysis_neighborhoods):\n",
    "    \"\"\"HOTFIX since I'm doing non spatial calculations in polars\"\"\"\n",
    "    df = analysis_neighborhoods[[\"analysis_neighborhood\", \"geometry\"]].merge(\n",
    "        df.to_pandas(), how=\"right\", on=\"analysis_neighborhood\"\n",
    "    )\n",
    "    df[\"northeast_core\"] = df[\"analysis_neighborhood\"].isin(\n",
    "        northeast_core_analysis_neighborhoods\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot(\n",
    "    nhood_crashes,\n",
    "    accident_col,\n",
    "    save_filename_stem,\n",
    "    suptitle=None,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "):\n",
    "    _, ax = plt.subplots(3, figsize=(10, 10))\n",
    "    for i, severity in enumerate([\"injury only\", \"fatal\", \"combined\"]):\n",
    "        # no longer showing ped/bike/all accidents separately\n",
    "        # for j, accident_col in enumerate(accident_cols):\n",
    "        nhood_crashes.loc[nhood_crashes[\"severity\"] == severity].plot(\n",
    "            ax=ax[i], column=accident_col, legend=True, vmin=vmin, vmax=vmax\n",
    "        )\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.savefig(f\"output/Links/{save_filename_stem}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO see if the data in \"Q:\\Data\\Observed\\Streets\\Safety\\SWITRS\\San Francisco Data from TIMS\" works for this\n",
    "tims_crashes_filepath = r\"C:\\Users\\cchow\\Desktop\\tmp\\downtown_today\\safety\\TIMS-SWITRS-crashes-2014-2023.csv\"\n",
    "# crashes only include crashes where injuries/deaths happened\n",
    "crashes = (\n",
    "    pl.read_csv(\n",
    "        tims_crashes_filepath,\n",
    "        columns=[\n",
    "            \"ACCIDENT_YEAR\",\n",
    "            # \"COLLISION_DATE\",\n",
    "            # \"COLLISION_TIME\",  # some times, e.g. \"43\" or \"20\" is unparseable\n",
    "            \"DAY_OF_WEEK\",\n",
    "            \"NUMBER_KILLED\",\n",
    "            \"NUMBER_INJURED\",\n",
    "            \"PEDESTRIAN_ACCIDENT\",\n",
    "            \"BICYCLE_ACCIDENT\",\n",
    "            \"LATITUDE\",\n",
    "            \"LONGITUDE\",\n",
    "            \"POINT_X\",\n",
    "            \"POINT_Y\",\n",
    "        ],\n",
    "        schema_overrides={\n",
    "            \"COLLISION_TIME\": str,\n",
    "            \"NUMBER_KILLED\": int,\n",
    "            \"NUMBER_INJURED\": int,\n",
    "        },\n",
    "    )\n",
    "    .filter((pl.col(\"NUMBER_INJURED\") > 0) | (pl.col(\"NUMBER_KILLED\") > 0))\n",
    "    .select(\n",
    "        \"ACCIDENT_YEAR\",\n",
    "        \"DAY_OF_WEEK\",\n",
    "        (pl.col(\"PEDESTRIAN_ACCIDENT\") == \"Y\").fill_null(False),  # cast to bool\n",
    "        (pl.col(\"BICYCLE_ACCIDENT\") == \"Y\").fill_null(False),  # cast to bool\n",
    "        severity=(\n",
    "            pl.when(pl.col(\"NUMBER_KILLED\") > 0)\n",
    "            .then(pl.lit(\"fatal\"))\n",
    "            .otherwise(pl.lit(\"injury only\"))\n",
    "        ),\n",
    "        LATITUDE=pl.when(pl.col(\"LATITUDE\").is_not_null())\n",
    "        .then(pl.col(\"LATITUDE\"))\n",
    "        .otherwise(pl.col(\"POINT_Y\")),\n",
    "        LONGITUDE=pl.when(pl.col(\"LONGITUDE\").is_not_null())\n",
    "        .then(pl.col(\"LONGITUDE\"))\n",
    "        .otherwise(pl.col(\"POINT_X\")),\n",
    "    )\n",
    ")\n",
    "\n",
    "analysis_neighborhoods = gpd.read_file(\n",
    "    r\"Q:\\GIS\\Policy\\San_Francisco\\Analysis_Neighborhoods\\Analysis Neighborhoods_20240610.zip\"\n",
    ").rename(columns={\"nhood\": \"analysis_neighborhood\"})\n",
    "analysis_neighborhoods[\"area_sqmi\"] = (\n",
    "    analysis_neighborhoods.to_crs(\"EPSG:7132\").area / 27878400  # 7132: SF CRS (ft)\n",
    ")\n",
    "# or we can do accidents per street mile:\n",
    "# street_centrelines = gpd.read_file(\n",
    "#     r\"Q:\\GIS\\Transportation\\Roads\\San_Francisco\\Street_Centerlines\\2022_clean\"\n",
    "# )\n",
    "\n",
    "crashes = (\n",
    "    gpd.GeoDataFrame(\n",
    "        crashes.to_pandas(),\n",
    "        geometry=gpd.points_from_xy(crashes[\"LONGITUDE\"], crashes[\"LATITUDE\"]),\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    .sjoin(analysis_neighborhoods, how=\"left\", predicate=\"within\")\n",
    "    .drop(columns=\"index_right\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crashes.plot(column=\"analysis_neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excludes collisions that are e.g. on bridges within SF County but not within any\n",
    "# analysis neighborhood. My guess is those should NOT be ped/bike collisions anyways\n",
    "# the following code plots these collisions not in any analysis neighborhood:\n",
    "# crashes.loc[crashes[\"analysis_neighborhood\"].isnull(), \"analysis_neighborhood\"] = \"N/A\"\n",
    "# crashes[\n",
    "#     (crashes[\"LONGITUDE\"] > -123)\n",
    "#     & (crashes[\"LONGITUDE\"] < -122)\n",
    "#     & (crashes[\"LATITUDE\"] > 37.5)\n",
    "#     & (crashes[\"LATITUDE\"] < 38)\n",
    "# ].plot(column=\"analysis_neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOTFIX cast to pl then back to gpd as I'm more comfortable with pl syntax\n",
    "crashes_grouped = sum_ped_and_bike(\n",
    "    group_crashes(  # group into analysis neighborhoods\n",
    "        # HOTFIX remove geometry col to cast to polars\n",
    "        pl.from_pandas(crashes.drop(columns=\"geometry\"))\n",
    "        .with_columns(\n",
    "            # group years into 2 year periods around COVID\n",
    "            # (doing 2 year periods to get better statistics with the larger sums)\n",
    "            covid_period=pl.when(pl.col(\"ACCIDENT_YEAR\").is_in([2018, 2019]))\n",
    "            .then(pl.lit(\"2018-2019\"))\n",
    "            .when(pl.col(\"ACCIDENT_YEAR\").is_in([2020, 2021]))\n",
    "            .then(pl.lit(\"2020-2021\"))\n",
    "            .when(pl.col(\"ACCIDENT_YEAR\").is_in([2022, 2023]))\n",
    "            .then(pl.lit(\"2022-2023\"))\n",
    "        )\n",
    "        # drop the years not around COVID, and locations not in analysis neighborhoods\n",
    "        .drop_nulls(),\n",
    "        \"covid_period\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# nhood = shorthand for analysis neighborhood\n",
    "crashes_nhood_change = calculate_covid_change(crashes_grouped, \"analysis_neighborhood\")\n",
    "# HOTFIX add back geometry column\n",
    "crashes_grouped = add_analysis_neighborhood_geometry(\n",
    "    crashes_grouped, analysis_neighborhoods\n",
    ")\n",
    "crashes_nhood_change = add_analysis_neighborhood_geometry(\n",
    "    crashes_nhood_change, analysis_neighborhoods\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_ne_core_grouped = pl.from_pandas(\n",
    "    crashes_grouped.groupby([\"northeast_core\", \"severity\", \"covid_period\"])\n",
    "    .agg({\"area_sqmi\": \"sum\", \"PED_AND_BIKE_ACCIDENT\": \"sum\"})\n",
    "    .assign(\n",
    "        PED_AND_BIKE_ACCIDENT_per_sqmi=lambda df: df.PED_AND_BIKE_ACCIDENT\n",
    "        / df.area_sqmi\n",
    "    ),\n",
    "    include_index=True,\n",
    ")\n",
    "crashes_ne_core_change = calculate_covid_change(\n",
    "    crashes_ne_core_grouped, \"northeast_core\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_grouped.to_file(\"output/data/crashes.gpkg\")\n",
    "crashes_nhood_change.to_file(\"output/data/crashes-change.gpkg\")\n",
    "crashes_ne_core_grouped.write_csv(\"output/data/crashes-northeast_core.csv\")\n",
    "crashes_ne_core_change.write_csv(\"output/data/crashes-northeast_core-change.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_core_pct_change_chart = (\n",
    "    crashes_ne_core_change.filter(pl.col(\"severity\").is_in([\"injury only\", \"fatal\"]))\n",
    "    .plot.bar(\n",
    "        x=\"severity\",\n",
    "        y=\"PED_AND_BIKE_ACCIDENT_1819_to_2223_pct_change\",\n",
    "        color=\"northeast_core\",\n",
    "        xOffset=\"northeast_core\",\n",
    "    )\n",
    "    .properties(title=\"pct change in ped+bike collisions 18/19 vs 22/23\")\n",
    ")\n",
    "ne_core_pct_change_chart.save(\"output/Links/crashes-by_northeast_core-change.png\")\n",
    "ne_core_pct_change_chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_core_chart = (\n",
    "    alt.Chart(\n",
    "        crashes_ne_core_grouped.filter(\n",
    "            pl.col(\"covid_period\").is_in([\"2018-2019\", \"2022-2023\"])\n",
    "            & pl.col(\"severity\").is_in([\"injury only\"])\n",
    "        )\n",
    "    )\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"covid_period:N\"),\n",
    "        xOffset=\"northeast_core:N\",\n",
    "        y=alt.Y(\"PED_AND_BIKE_ACCIDENT_per_sqmi:Q\"),\n",
    "        color=alt.Color(\"northeast_core:N\"),\n",
    "    )\n",
    "    .properties(title=\"ped & bike accidents per sqmi (injury only)\")\n",
    ") | (\n",
    "    alt.Chart(\n",
    "        crashes_ne_core_grouped.filter(\n",
    "            pl.col(\"covid_period\").is_in([\"2018-2019\", \"2022-2023\"])\n",
    "            & pl.col(\"severity\").is_in([\"fatal\"])\n",
    "        )\n",
    "    )\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"covid_period:N\"),\n",
    "        xOffset=\"northeast_core:N\",\n",
    "        y=alt.Y(\"PED_AND_BIKE_ACCIDENT_per_sqmi:Q\"),\n",
    "        color=alt.Color(\"northeast_core:N\"),\n",
    "    )\n",
    "    .properties(title=\"ped & bike accidents per sqmi (fatal)\")\n",
    ")  # .resolve_scale(y=\"shared\")\n",
    "ne_core_chart.save(\"output/Links/crashes-by_northeast_core.png\")\n",
    "ne_core_chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, (severity, vmax) in enumerate(\n",
    "    zip([\"injury only\", \"fatal\", \"combined\"], [600, 16, 650])\n",
    "):\n",
    "    for j, covid_period in enumerate([\"2018-2019\", \"2020-2021\", \"2022-2023\"]):\n",
    "        crashes_grouped.loc[\n",
    "            (crashes_grouped[\"severity\"] == severity)\n",
    "            & (crashes_grouped[\"covid_period\"] == covid_period)\n",
    "        ].plot(\n",
    "            ax=ax[i, j],\n",
    "            column=\"PED_AND_BIKE_ACCIDENT_per_sqmi\",\n",
    "            legend=True,\n",
    "            vmin=0,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "plt.suptitle(\n",
    "    \"ped+bike crashes per sqmi: 18/19 vs 20/21 vs 22/23\\n\"\n",
    "    \"rows = injury only, fatal, combined\\ncols = 18/19, 20/21, 22/23\\n\"\n",
    "    \"holes = NaN = 0 to 0\"\n",
    ")\n",
    "plt.savefig(\"output/Links/crashes-by_analysis_neighborhood.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for i, severity in enumerate(\n",
    "    [\n",
    "        \"injury only\",\n",
    "        # \"fatal\",\n",
    "        \"combined\",\n",
    "    ]\n",
    "):\n",
    "    for j, (col, vminmax) in enumerate(\n",
    "        zip(\n",
    "            [\n",
    "                \"PED_AND_BIKE_ACCIDENT_per_sqmi_1819_to_2223_diff\",\n",
    "                \"PED_AND_BIKE_ACCIDENT_1819_to_2223_pct_change\",\n",
    "            ],\n",
    "            [180, 150],\n",
    "        )\n",
    "    ):\n",
    "        crashes_nhood_change.loc[crashes_nhood_change[\"severity\"] == severity].plot(\n",
    "            ax=ax[i, j],\n",
    "            column=col,\n",
    "            legend=True,\n",
    "            vmin=-vminmax,\n",
    "            vmax=vminmax,\n",
    "            cmap=\"coolwarm\",\n",
    "        )\n",
    "plt.suptitle(\n",
    "    \"ped+bike crashes: 18/19 vs 22/23\\n\"\n",
    "    \"rows = injury only, combined\\ncols = diff, pct change\\n\"\n",
    "    \"holes = NaN = '0 to 0'\"\n",
    ")\n",
    "plt.savefig(\"output/Links/crashes-by_analysis_neighborhood-1819v2223.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
