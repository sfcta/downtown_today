{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO see if the data in \"Q:\\Data\\Observed\\Streets\\Safety\\SWITRS\\San Francisco Data from TIMS\" works for this\n",
    "tims_crashes_filepath = r\"C:\\Users\\cchow\\Desktop\\tmp\\downtown_today\\safety\\TIMS-SWITRS-crashes-2014-2023.csv\"\n",
    "# crashes only include crashes where injuries/deaths happened\n",
    "crashes = (\n",
    "    pl.read_csv(\n",
    "        tims_crashes_filepath,\n",
    "        columns=[\n",
    "            \"ACCIDENT_YEAR\",\n",
    "            # \"COLLISION_DATE\",\n",
    "            # \"COLLISION_TIME\",  # some times, e.g. \"43\" or \"20\" is unparseable\n",
    "            \"DAY_OF_WEEK\",\n",
    "            \"NUMBER_KILLED\",\n",
    "            \"NUMBER_INJURED\",\n",
    "            \"PEDESTRIAN_ACCIDENT\",\n",
    "            \"BICYCLE_ACCIDENT\",\n",
    "            \"LATITUDE\",\n",
    "            \"LONGITUDE\",\n",
    "            \"POINT_X\",\n",
    "            \"POINT_Y\",\n",
    "        ],\n",
    "        schema_overrides={\n",
    "            \"COLLISION_TIME\": str,\n",
    "            \"NUMBER_KILLED\": int,\n",
    "            \"NUMBER_INJURED\": int,\n",
    "        },\n",
    "    )\n",
    "    .filter((pl.col(\"NUMBER_INJURED\") > 0) | (pl.col(\"NUMBER_KILLED\") > 0))\n",
    "    .select(\n",
    "        \"ACCIDENT_YEAR\",\n",
    "        \"DAY_OF_WEEK\",\n",
    "        (pl.col(\"PEDESTRIAN_ACCIDENT\") == \"Y\").fill_null(False),  # cast to bool\n",
    "        (pl.col(\"BICYCLE_ACCIDENT\") == \"Y\").fill_null(False),  # cast to bool\n",
    "        severity=(\n",
    "            pl.when(pl.col(\"NUMBER_KILLED\") > 0)\n",
    "            .then(pl.lit(\"fatal\"))\n",
    "            .otherwise(pl.lit(\"injury only\"))\n",
    "        ),\n",
    "        LATITUDE=pl.when(pl.col(\"LATITUDE\").is_not_null())\n",
    "        .then(pl.col(\"LATITUDE\"))\n",
    "        .otherwise(pl.col(\"POINT_Y\")),\n",
    "        LONGITUDE=pl.when(pl.col(\"LONGITUDE\").is_not_null())\n",
    "        .then(pl.col(\"LONGITUDE\"))\n",
    "        .otherwise(pl.col(\"POINT_X\")),\n",
    "    )\n",
    ")\n",
    "\n",
    "analysis_neighborhoods = gpd.read_file(\n",
    "    r\"Q:\\GIS\\Policy\\San_Francisco\\Analysis_Neighborhoods\\Analysis Neighborhoods_20240610.zip\"\n",
    ").rename(columns={\"nhood\": \"analysis_neighborhood\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes = (\n",
    "    gpd.GeoDataFrame(\n",
    "        crashes.to_pandas(),\n",
    "        geometry=gpd.points_from_xy(crashes[\"LONGITUDE\"], crashes[\"LATITUDE\"]),\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    .sjoin(analysis_neighborhoods, how=\"left\", predicate=\"within\")\n",
    "    .drop(columns=\"index_right\")\n",
    ")\n",
    "# crashes.plot(column=\"analysis_neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excludes collisions that are e.g. on bridges within SF County but not within any\n",
    "# analysis neighborhood. My guess is those should NOT be ped/bike collisions anyways\n",
    "# the following code plots these collisions not in any analysis neighborhood:\n",
    "# crashes.loc[crashes[\"analysis_neighborhood\"].isnull(), \"analysis_neighborhood\"] = \"N/A\"\n",
    "# crashes[\n",
    "#     (crashes[\"LONGITUDE\"] > -123)\n",
    "#     & (crashes[\"LONGITUDE\"] < -122)\n",
    "#     & (crashes[\"LATITUDE\"] > 37.5)\n",
    "#     & (crashes[\"LATITUDE\"] < 38)\n",
    "# ].plot(column=\"analysis_neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_combos(crashes: pl.DataFrame, group_by_cols):\n",
    "    \"\"\"\n",
    "    Some groups have no crashes. This make sures these groups still have a row of 0s.\n",
    "    \"\"\"\n",
    "    # create a single row df with each col being a list of the unique values of that col\n",
    "    cross_product_df = crashes.select(pl.col(group_by_cols).unique().implode())\n",
    "    # create a cross product of the unique values of these cols\n",
    "    for col in group_by_cols:\n",
    "        # explode explodes the lists in each of these cols back out to different rows\n",
    "        cross_product_df = cross_product_df.explode(col)\n",
    "    return cross_product_df.join(\n",
    "        crashes, how=\"left\", on=group_by_cols, coalesce=True\n",
    "    ).fill_null(0)\n",
    "\n",
    "\n",
    "def group_crashes(crashes: pl.DataFrame, time_col: str):\n",
    "    group_by_cols = [time_col, \"analysis_neighborhood\", \"severity\"]\n",
    "    crashes_grouped = generate_all_combos(\n",
    "        crashes.group_by(group_by_cols).agg(\n",
    "            pl.sum(\"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\"),\n",
    "            ALL_ACCIDENT=pl.len(),\n",
    "        ),\n",
    "        group_by_cols,\n",
    "    )\n",
    "    # also calculate number of injury only + fatal crashes\n",
    "    return pl.concat(\n",
    "        [\n",
    "            crashes_grouped,\n",
    "            crashes_grouped.group_by(\"covid_period\", \"analysis_neighborhood\")\n",
    "            .sum()\n",
    "            .with_columns(severity=pl.lit(\"combined\")),\n",
    "        ]\n",
    "    ).sort(group_by_cols)\n",
    "\n",
    "\n",
    "def calculate_covid_pct_change(crashes_grouped: pl.DataFrame):\n",
    "    return (\n",
    "        crashes_grouped.filter(pl.col(\"covid_period\").is_in([\"2018-2019\", \"2022-2023\"]))\n",
    "        .sort(\"analysis_neighborhood\", \"severity\", \"covid_period\")\n",
    "        .with_columns(\n",
    "            # calculate % change with previous row\n",
    "            pl.col(\"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\", \"ALL_ACCIDENT\")\n",
    "            .pct_change()\n",
    "            .name.suffix(\"_1819_to_2223_pct_change\")\n",
    "        )\n",
    "        # only select every 2nd row (i.e. the post-covid rows)\n",
    "        .filter(pl.col(\"covid_period\") == \"2022-2023\")\n",
    "        .drop(\"covid_period\", \"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\", \"ALL_ACCIDENT\")\n",
    "    )\n",
    "\n",
    "\n",
    "def add_analysis_neighborhood_geometry(df, analysis_neighborhoods):\n",
    "    \"\"\"HOTFIX since I'm doing non spatial calculations in polars\"\"\"\n",
    "    return analysis_neighborhoods.merge(\n",
    "        df.to_pandas(), how=\"right\", on=\"analysis_neighborhood\"\n",
    "    )\n",
    "\n",
    "\n",
    "def plot(\n",
    "    nhood_crashes,\n",
    "    accident_cols,\n",
    "    save_filename_stem,\n",
    "    suptitle=None,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "):\n",
    "    _, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    for i, severity in enumerate([\"injury only\", \"fatal\", \"combined\"]):\n",
    "        for j, accident_col in enumerate(accident_cols):\n",
    "            nhood_crashes.loc[nhood_crashes[\"severity\"] == severity].plot(\n",
    "                ax=ax[i, j], column=accident_col, legend=True, vmin=vmin, vmax=vmax\n",
    "            )\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.savefig(f\"output/Links/{save_filename_stem}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOTFIX cast to pl then back to gpd as I'm more comfortable with pl syntax\n",
    "crashes_grouped = (\n",
    "    # group into analysis neighborhoods\n",
    "    group_crashes(\n",
    "        # HOTFIX remove geometry col to cast to polars\n",
    "        pl.from_pandas(crashes.drop(columns=\"geometry\"))\n",
    "        .with_columns(\n",
    "            # group years into 2 year periods around COVID\n",
    "            # (doing 2 year periods to get better statistics with the larger sums)\n",
    "            covid_period=pl.when(pl.col(\"ACCIDENT_YEAR\").is_in([2018, 2019]))\n",
    "            .then(pl.lit(\"2018-2019\"))\n",
    "            .when(pl.col(\"ACCIDENT_YEAR\").is_in([2020, 2021]))\n",
    "            .then(pl.lit(\"2020-2021\"))\n",
    "            .when(pl.col(\"ACCIDENT_YEAR\").is_in([2022, 2023]))\n",
    "            .then(pl.lit(\"2022-2023\"))\n",
    "        )\n",
    "        # drop the years not around COVID, and locations not in analysis neighborhoods\n",
    "        .drop_nulls(),\n",
    "        \"covid_period\",\n",
    "    )\n",
    ")\n",
    "# nhood = shorthand for analysis neighborhood\n",
    "crashes_nhood_pct_change = calculate_covid_pct_change(crashes_grouped)\n",
    "# HOTFIX add back geometry column\n",
    "crashes_grouped = add_analysis_neighborhood_geometry(\n",
    "    crashes_grouped, analysis_neighborhoods\n",
    ")\n",
    "crashed_nhood_pct_change = add_analysis_neighborhood_geometry(\n",
    "    crashes_nhood_pct_change, analysis_neighborhoods\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_grouped.to_file(\"output/data/crashes.gpkg\")\n",
    "crashed_nhood_pct_change.to_file(\"output/data/crashes-pct_change.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    crashes_grouped.loc[crashes_grouped[\"covid_period\"] == \"2018-2019\"],\n",
    "    [\"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\", \"ALL_ACCIDENT\"],\n",
    "    \"crashes-by_analysis_neighborhood-1819\",\n",
    "    suptitle=(\n",
    "        \"2018/2019 crashes\\n\"\n",
    "        \"rows = injury only, fatal, combined\\ncols = ped, bike, all\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    crashes_grouped.loc[crashes_grouped[\"covid_period\"] == \"2020-2021\"],\n",
    "    [\"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\", \"ALL_ACCIDENT\"],\n",
    "    \"crashes-by_analysis_neighborhood-2021\",\n",
    "    suptitle=(\n",
    "        \"2020/2021 crashes\\n\"\n",
    "        \"rows = injury only, fatal, combined\\ncols = ped, bike, all\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    crashes_grouped.loc[crashes_grouped[\"covid_period\"] == \"2022-2023\"],\n",
    "    [\"PEDESTRIAN_ACCIDENT\", \"BICYCLE_ACCIDENT\", \"ALL_ACCIDENT\"],\n",
    "    \"crashes-by_analysis_neighborhood-2223\",\n",
    "    suptitle=(\n",
    "        \"2022/2023 crashes\\n\"\n",
    "        \"rows = injury only, fatal, combined\\ncols = ped, bike, all\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    crashed_nhood_pct_change,\n",
    "    [\n",
    "        \"PEDESTRIAN_ACCIDENT_1819_to_2223_pct_change\",\n",
    "        \"BICYCLE_ACCIDENT_1819_to_2223_pct_change\",\n",
    "        \"ALL_ACCIDENT_1819_to_2223_pct_change\",\n",
    "    ],\n",
    "    \"crashes-by_analysis_neighborhood-pct_change_1819v2223\",\n",
    "    suptitle=(\n",
    "        \"pct change 18/19 vs 22/23\\n\"\n",
    "        \"rows = injury only, fatal, combined\\ncols = ped, bike, all\\n values capped at (-1, 1)\\n\"\n",
    "        \"holes = NaN = 0 to 0\"\n",
    "    ),\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
